1、样本严重不均衡会导致分类器无效。一般不均衡比例超过4：1，分类器就会偏向于大的类别
解决样本不均衡
（a）扩充样本集
（b）重采样：对样本少的过采样，对样本多的欠采样；
     但放大或缩小某些样本的影响相当于改变原数据集的分布，可能会增大模型的偏差。
（c）人造数据：像SMOTE算法，基于距离度量选择小类别下的两个或者更多的相似样本，然后选择其中一个样本
    并随机选择一定数量的邻居样本对所选择的样本进行插值构造新的样本
（d）使用加权的softmax loss
 2、第一层的filter数量不要太少
 3、loss为NaN
 （a）loss随着每轮迭代越来越大，最终超过范围变为NaN;
      措施：较少学习率，多标签有多个损失函数层，则要找出是哪个损失层，减少该层的权重
 （b)loss逐渐降低，NaN突然出现，由于损失函数loss计算导致NaN出现，或由于输入数据有坏数据，导致梯度爆炸
 （c）还可能和初始化有关，jiayangqing说初始化不好，lr=0.00001，loss都可能很大；
 4、loss为87.336；遇到87.336，后面会一直是这个数字
    softmax 利用指数计算，指数函数的值都比0大，说明计算出现了float溢出，像出现inf,nan，这样会导致softmax
    输出0，softmax之前的特征值过大，先求指数就会超过范围
    解决：特征一部门是数据，一部分是权重；
    （a）是否有异常样本或异常标签
    （b）降低学习率，从而减少权重波动
    （c）降低初始化权重，使输入到softmax的特征变小
    （d）含有BN层，在微调时不要冻结BN的参数，数据分布不一致会使输出值变的很大
